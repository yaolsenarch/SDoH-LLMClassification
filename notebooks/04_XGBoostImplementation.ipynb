{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89745b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python path: ['/usr/lib64/python311.zip', '/usr/lib64/python3.11', '/usr/lib64/python3.11/lib-dynload', '', '/proj/sas/ripython/venv_311/lib64/python3.11/site-packages', '/proj/sas/ripython/venv_311/lib/python3.11/site-packages']\n",
      "\n",
      "llm_utils location: /proj/sas/ripython/LLMClassfication/llm_utils.py\n",
      "\n",
      "Contents of llm_utils: ['AzureOpenAI', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'ast', 'calculate_disagreement_score', 'calculate_multilabel_metrics', 'cohen_kappa_score', 'convert_gold_labels_to_list', 'create_2shot_hard_prompt', 'generate_explanation_for_easy_example', 'generate_explanation_for_hard_example', 'get_prompt_template', 'get_strengthened_prompt_template', 'json', 'np', 'os', 'parse_llm_labels', 'precision_recall_fscore_support', 're', 'run_llm_annotation', 'run_zero_shot_and_score', 'select_easy_examples_automatically', 'select_hard_examples_automatically', 'time']\n",
      "\n",
      "After reload - Contents of llm_utils: ['AzureOpenAI', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'ast', 'calculate_disagreement_score', 'calculate_multilabel_metrics', 'cohen_kappa_score', 'convert_gold_labels_to_list', 'create_2shot_hard_prompt', 'generate_explanation_for_easy_example', 'generate_explanation_for_hard_example', 'get_prompt_template', 'get_strengthened_prompt_template', 'json', 'np', 'os', 'parse_llm_labels', 'precision_recall_fscore_support', 're', 'run_llm_annotation', 'run_zero_shot_and_score', 'select_easy_examples_automatically', 'select_hard_examples_automatically', 'time']\n"
     ]
    }
   ],
   "source": [
    "# Try importing with debug info\n",
    "import sys\n",
    "print(\"Python path:\", sys.path)\n",
    "\n",
    "import llm_utils\n",
    "print(\"\\nllm_utils location:\", llm_utils.__file__)\n",
    "print(\"\\nContents of llm_utils:\", dir(llm_utils))\n",
    "\n",
    "# Try reloading the module to get latest changes\n",
    "import importlib\n",
    "importlib.reload(llm_utils)\n",
    "print(\"\\nAfter reload - Contents of llm_utils:\", dir(llm_utils))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42d7776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI\n",
    "import time\n",
    "from sdoh_data import load_sdoh_dataset   # ‚úÖ your helper module\n",
    "from llm_utils import (parse_llm_labels, run_llm_annotation, calculate_disagreement_score, run_zero_shot_and_score,select_hard_examples_automatically,\n",
    "                        generate_explanation_for_hard_example, create_2shot_hard_prompt, select_easy_examples_automatically, generate_explanation_for_easy_example,\n",
    "                        calculate_multilabel_metrics, get_strengthened_prompt_template)\n",
    "from sklearn.metrics import precision_recall_fscore_support, cohen_kappa_score\n",
    "import llm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e9130",
   "metadata": {},
   "source": [
    "### üìö Load the saved progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f239d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint!\n",
      "‚úì Hard examples: 2\n",
      "‚úì Easy positive: The patient smokes about a pack a day for more tha...\n",
      "‚úì Easy negative: She has never used illicit drugs...\n",
      "‚úì Test set size: 200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load saved progress\n",
    "with open('procgress_checkpoint_step61.pkl', 'rb') as f:\n",
    "    save_data = pickle.load(f)\n",
    "# Extract the variables\n",
    "hard_examples = save_data['hard_examples']\n",
    "easy_positive = save_data['easy_positive']\n",
    "easy_negative = save_data['easy_negative']\n",
    "test_df = save_data['test_df']\n",
    "results_50 = save_data['results_50']\n",
    "categories = save_data['categories']\n",
    "\n",
    "# Verify what we loaded\n",
    "print(\"Loaded checkpoint!\")\n",
    "print(f\"‚úì Hard examples: {len(hard_examples)}\")\n",
    "print(f\"‚úì Easy positive: {easy_positive['premise'][:50]}...\")\n",
    "print(f\"‚úì Easy negative: {easy_negative['premise'][:50]}...\")\n",
    "print(f\"‚úì Test set size: {len(test_df)}\")\n",
    "print()\n",
    "\n",
    "# Package easy examples as tuple for the function\n",
    "easy_examples = (easy_positive, easy_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0caf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded full evaluation results!\n",
      "Configurations evaluated: ['0-Shot', '2-Shot Easy', '2-Shot Easy + Exp', '2-Shot Hard', '2-Shot Hard + Exp']\n",
      "Samples per configuration: 200\n",
      "0-Shot:\n",
      "  Total predictions: 200\n",
      "  Sample prediction: [\"employment\"]\n",
      "2-Shot Easy:\n",
      "  Total predictions: 200\n",
      "  Sample prediction: []\n",
      "2-Shot Easy + Exp:\n",
      "  Total predictions: 200\n",
      "  Sample prediction: [\"employment\"]\n",
      "2-Shot Hard:\n",
      "  Total predictions: 200\n",
      "  Sample prediction: []\n",
      "2-Shot Hard + Exp:\n",
      "  Total predictions: 200\n",
      "  Sample prediction: []\n"
     ]
    }
   ],
   "source": [
    "# Load full evaluation results\n",
    "with open('full_evaluation_results.pkl', 'rb') as f:\n",
    "    full_results = pickle.load(f)   \n",
    "print(\"Loaded full evaluation results!\")\n",
    "print(f\"Configurations evaluated: {list(full_results.keys())}\")\n",
    "print(f\"Samples per configuration: {len(full_results['0-Shot'])}\")\n",
    "\n",
    "\n",
    "# sanity check\n",
    "for config_name, predictions in full_results.items():\n",
    "    print(f\"{config_name}:\")\n",
    "    print(f\"  Total predictions: {len(predictions)}\")\n",
    "    print(f\"  Sample prediction: {predictions[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed0b8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0-Shot': {'precision_micro': 0.4088669950738916,\n",
       "  'recall_micro': 0.9764705882352941,\n",
       "  'f1_micro': 0.5763888888888888,\n",
       "  'precision_macro': 0.4991309523809523,\n",
       "  'recall_macro': 0.8523809523809522,\n",
       "  'f1_macro': 0.5784651918236949,\n",
       "  'exact_match_accuracy': 0.535,\n",
       "  'hamming_loss': np.float64(0.061),\n",
       "  'cohen_kappa': 0.5493914938410682},\n",
       " '2-Shot Easy': {'precision_micro': 0.7745098039215687,\n",
       "  'recall_micro': 0.9294117647058824,\n",
       "  'f1_micro': 0.8449197860962567,\n",
       "  'precision_macro': 0.6760714285714284,\n",
       "  'recall_macro': 0.732034632034632,\n",
       "  'f1_macro': 0.684804353003303,\n",
       "  'exact_match_accuracy': 0.865,\n",
       "  'hamming_loss': np.float64(0.0145),\n",
       "  'cohen_kappa': 0.8373801379465037},\n",
       " '2-Shot Easy + Exp': {'precision_micro': 0.7297297297297297,\n",
       "  'recall_micro': 0.9529411764705882,\n",
       "  'f1_micro': 0.826530612244898,\n",
       "  'precision_macro': 0.6824906245958877,\n",
       "  'recall_macro': 0.7493506493506492,\n",
       "  'f1_macro': 0.6927342516638292,\n",
       "  'exact_match_accuracy': 0.845,\n",
       "  'hamming_loss': np.float64(0.017),\n",
       "  'cohen_kappa': 0.8177578859914775},\n",
       " '2-Shot Hard': {'precision_micro': 0.7053571428571429,\n",
       "  'recall_micro': 0.9294117647058824,\n",
       "  'f1_micro': 0.8020304568527918,\n",
       "  'precision_macro': 0.6765989159891598,\n",
       "  'recall_macro': 0.732034632034632,\n",
       "  'f1_macro': 0.6797688993341167,\n",
       "  'exact_match_accuracy': 0.82,\n",
       "  'hamming_loss': np.float64(0.0195),\n",
       "  'cohen_kappa': 0.7919778109665031},\n",
       " '2-Shot Hard + Exp': {'precision_micro': 0.6694214876033058,\n",
       "  'recall_micro': 0.9529411764705882,\n",
       "  'f1_micro': 0.7864077669902912,\n",
       "  'precision_macro': 0.6598631098631098,\n",
       "  'recall_macro': 0.7493506493506492,\n",
       "  'f1_macro': 0.6811428571428572,\n",
       "  'exact_match_accuracy': 0.8,\n",
       "  'hamming_loss': np.float64(0.022),\n",
       "  'cohen_kappa': 0.7751833022507217}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your saved progress\n",
    "with open('all_metrics.pkl', 'rb') as f:\n",
    "    all_metrics=pickle.load(f) \n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9abee4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final model saved to: final_best_model_f1_094.pkl\n",
      "\n",
      "Final Performance:\n",
      "  F1 (micro):     0.940\n",
      "  F1 (macro):     0.648\n",
      "  Precision:      0.952\n",
      "  Recall:         0.929\n",
      "  Cohen's Kappa:  0.938\n",
      "  Exact Match:    0.950\n",
      "  Accuracy:       95.0%\n",
      "  Errors:         10/200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('final_best_model_f1_094.pkl', 'rb') as f:\n",
    "    final_best_model=pickle.load(f)\n",
    "print(\"‚úÖ Final model saved to: final_best_model_f1_094.pkl\")\n",
    "print()\n",
    "print(\"Final Performance:\")\n",
    "print(f\"  F1 (micro):     {final_best_model['f1_micro']:.3f}\")\n",
    "print(f\"  F1 (macro):     {final_best_model['f1_macro']:.3f}\")\n",
    "print(f\"  Precision:      {final_best_model['precision_micro']:.3f}\")\n",
    "print(f\"  Recall:         {final_best_model['recall_micro']:.3f}\")\n",
    "print(f\"  Cohen's Kappa:  {final_best_model['cohen_kappa']:.3f}\")\n",
    "print(f\"  Exact Match:    {final_best_model['exact_match']:.3f}\")\n",
    "print(f\"  Accuracy:       {final_best_model['accuracy']:.1%}\")\n",
    "print(f\"  Errors:         {final_best_model['errors']}/200\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288decc",
   "metadata": {},
   "source": [
    "### üöÄ XGBoost Implementation Plan<br>\n",
    "Phase 1: Label 320 Unused Samples with GPT-4o-mini v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c831092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same 2-Shot Easy prompt that worked best for GPT-3.5\n",
    "examples_easy_no_exp = f\"\"\"\n",
    "Example 1 (Positive):\n",
    "Premise: \"{easy_positive['premise']}\"\n",
    "Answer: {parse_llm_labels(easy_positive['gold_labels'])}\n",
    "\n",
    "Example 2 (Negative):\n",
    "Premise: \"{easy_negative['premise']}\"\n",
    "Answer: {parse_llm_labels(easy_negative['gold_labels'])}\n",
    "\"\"\"\n",
    "original_template = llm_utils.get_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22edda68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 1: LABELING 320 UNUSED SAMPLES WITH GPT-4o-mini v3\n",
      "======================================================================\n",
      "\n",
      "Full dataset size: 570\n",
      "\n",
      "Unused samples: 320\n",
      "Used samples: 250\n",
      "Total: 570\n",
      "\n",
      "‚úì Verified: 320 unused samples ready for labeling\n",
      "\n",
      "Labeling 320 samples with GPT-4o-mini v3 (strengthened prompt)...\n",
      "Estimated time: ~5-7 minutes\n",
      "Estimated cost: ~$0.50\n",
      "\n",
      "‚úì Got 320 labels!\n",
      "\n",
      "Sample of labeled data:\n",
      "  1. 1-2 ppd Cigarettes...\n",
      "     Labels: ['smoking']\n",
      "  2. 2ppd smoker since his teens; quit 2 years ago...\n",
      "     Labels: ['smoking']\n",
      "  3. According to the chart, the patient also drinks wine everyda...\n",
      "     Labels: ['alcohol', 'drug_use']\n",
      "\n",
      "‚úì Phase 1 complete: 320 samples labeled with GPT-4o-mini v3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PHASE 1: LABELING 320 UNUSED SAMPLES WITH GPT-4o-mini v3\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Get the 320 unused samples\n",
    "# We used 50 for hard example selection + 200 for testing = 250 used\n",
    "# Total 570 - 250 = 320 remaining\n",
    "\n",
    "# Load original data\n",
    "# from sdoh_data import load_sdoh_dataset\n",
    "# df_full = load_sdoh_dataset()\n",
    "df_gold = pd.read_csv(\"annotations_with_gold.csv\")\n",
    "print(f\"Full dataset size: {len(df_gold)}\")\n",
    "print()\n",
    "\n",
    "# Identify unused samples (those not in results_50 or test_df)\n",
    "used_indices = set(results_50.index.tolist() + test_df.index.tolist())\n",
    "unused_mask = ~df_gold.index.isin(used_indices)\n",
    "df_unused = df_gold[unused_mask].copy()\n",
    "\n",
    "print(f\"Unused samples: {len(df_unused)}\")\n",
    "print(f\"Used samples: {len(used_indices)}\")\n",
    "print(f\"Total: {len(df_gold)}\")\n",
    "print()\n",
    "\n",
    "# Verify we have the right amount\n",
    "assert len(df_unused) == 320, f\"Expected 320 unused samples, got {len(df_unused)}\"\n",
    "\n",
    "print(\"‚úì Verified: 320 unused samples ready for labeling\")\n",
    "print()\n",
    "\n",
    "# Use same strengthened prompt that achieved F1=0.940\n",
    "llm_utils.get_prompt_template = get_strengthened_prompt_template\n",
    "\n",
    "print(\"Labeling 320 samples with GPT-4o-mini v3 (strengthened prompt)...\")\n",
    "print(\"Estimated time: ~5-7 minutes\")\n",
    "print(\"Estimated cost: ~$0.50\")\n",
    "print()\n",
    "\n",
    "# Label with GPT-4o-mini v3\n",
    "xgb_training_labels = run_llm_annotation(\n",
    "    df=df_unused,\n",
    "    categories=categories,\n",
    "    examples=examples_easy_no_exp,  # Same 2-shot easy examples\n",
    "    deployment_name=\"gpt-4o-mini\",\n",
    "    sleep_time=1\n",
    ")\n",
    "\n",
    "print(f\"‚úì Got {len(xgb_training_labels)} labels!\")\n",
    "print()\n",
    "\n",
    "# Parse labels\n",
    "xgb_training_labels_parsed = [parse_llm_labels(label) for label in xgb_training_labels]\n",
    "\n",
    "print(\"Sample of labeled data:\")\n",
    "for i in range(3):\n",
    "    print(f\"  {i+1}. {df_unused.iloc[i]['premise'][:60]}...\")\n",
    "    print(f\"     Labels: {xgb_training_labels_parsed[i]}\")\n",
    "print()\n",
    "\n",
    "# Save labeled training data\n",
    "df_unused['gpt4o_labels'] = xgb_training_labels\n",
    "df_unused['gpt4o_labels_parsed'] = xgb_training_labels_parsed\n",
    "\n",
    "# Restore template\n",
    "llm_utils.get_prompt_template = original_template\n",
    "\n",
    "print(\"‚úì Phase 1 complete: 320 samples labeled with GPT-4o-mini v3\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1194d04a",
   "metadata": {},
   "source": [
    "The above drug_use false alarm again in Sample 3. but it is consistent with the 4FP errors we saw earlier. GPT4o min occationally over apply the drug umbrella rule to alcohol <br>\n",
    "**But thats OK** XGBoost will learn from the aggregate samples across 320 samples and will correct these errors. Thats the beauty of statiscial learning!üéØ<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a25c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CHECKING GPT-4o-mini LABELING QUALITY ON 320 SAMPLES\n",
      "======================================================================\n",
      "\n",
      "Extracted gold labels for 320 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"CHECKING GPT-4o-mini LABELING QUALITY ON 320 SAMPLES\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "# Get gold labels for the 320 unused samples\n",
    "# These should already exist in df_unused from the original dataset\n",
    "df_gold['gold_labels_parsed'] = df_gold['gold_labels'].apply(parse_llm_labels)\n",
    "df_unused = df_gold[unused_mask].copy()\n",
    "print(f\"Extracted gold labels for {len(df_unused)} samples\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1bae150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4o-mini Performance on 320 Training Samples:\n",
      "  F1 (micro):     0.882\n",
      "  Cohen's Kappa:  0.876\n",
      "  Exact Match:    0.906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gold_labels_320=[label for label in df_unused['gold_labels_parsed']] \n",
    "\n",
    "# Calculate metrics: GPT-4o-mini vs Gold on 320 samples\n",
    "metrics_gpt4o_on_320 = calculate_multilabel_metrics(\n",
    "    gold_labels=gold_labels_320,\n",
    "    predicted_labels=xgb_training_labels_parsed,\n",
    "    categories=categories)\n",
    "\n",
    "print(\"GPT-4o-mini Performance on 320 Training Samples:\")\n",
    "print(f\"  F1 (micro):     {metrics_gpt4o_on_320['f1_micro']:.3f}\")\n",
    "print(f\"  Cohen's Kappa:  {metrics_gpt4o_on_320['cohen_kappa']:.3f}\")\n",
    "print(f\"  Exact Match:    {metrics_gpt4o_on_320['exact_match_accuracy']:.3f}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c74487f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors in training labels: 30/320 (9.4%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze errors in training data\n",
    "errors_in_training = []\n",
    "for i in range(len(gold_labels_320)):\n",
    "    if set(gold_labels_320[i]) != set(xgb_training_labels_parsed[i]):\n",
    "        errors_in_training.append(i)\n",
    "\n",
    "print(f\"Errors in training labels: {len(errors_in_training)}/{len(gold_labels_320)} ({len(errors_in_training)/len(gold_labels_320)*100:.1f}%)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf1d9a8",
   "metadata": {},
   "source": [
    "üöÄ Phase 2: Feature Engineering & XGBoost Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33da2d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 2: FEATURE ENGINEERING & XGBOOST TRAINING\n",
      "======================================================================\n",
      "\n",
      "‚úì XGBoost already installed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PHASE 2: FEATURE ENGINEERING & XGBOOST TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Install xgboost if needed\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    print(\"‚úì XGBoost already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing XGBoost...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call(['pip', 'install', 'xgboost'])\n",
    "    import xgboost as xgb\n",
    "    print(\"‚úì XGBoost installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7d45bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Prepare Training Data\n",
      "--------------------------------------------------\n",
      "Training samples: 320\n",
      "Test samples: 200\n",
      "\n",
      "Step 2: Convert Labels to Binary Format\n",
      "--------------------------------------------------\n",
      "Binary matrix shape: (320, 10)\n",
      "Categories: ['food' 'opioids' 'cocaine' 'smoking' 'marijuana' 'transportation'\n",
      " 'housing' 'employment' 'drug_use' 'alcohol']\n",
      "\n",
      "Training label distribution:\n",
      "  food           :   0 (0.0%)\n",
      "  opioids        :   2 (0.6%)\n",
      "  cocaine        :   2 (0.6%)\n",
      "  smoking        :  53 (16.6%)\n",
      "  marijuana      :   4 (1.2%)\n",
      "  transportation :   0 (0.0%)\n",
      "  housing        :   0 (0.0%)\n",
      "  employment     :  10 (3.1%)\n",
      "  drug_use       :  30 (9.4%)\n",
      "  alcohol        :  49 (15.3%)\n",
      "\n",
      "Step 3: Extract TF-IDF Features\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print()\n",
    "print(\"Step 1: Prepare Training Data\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Training data: 320 samples labeled by GPT-4o-mini\n",
    "X_train_text = df_unused['premise'].values\n",
    "y_train_labels = xgb_training_labels_parsed\n",
    "\n",
    "# Test data: 200 samples with gold labels\n",
    "X_test_text = test_df['premise'].values\n",
    "gold_labels_parsed=[\n",
    "    parse_llm_labels(label) for label in test_df['gold_labels']\n",
    "]\n",
    "y_test_labels = gold_labels_parsed\n",
    "\n",
    "print(f\"Training samples: {len(X_train_text)}\")\n",
    "print(f\"Test samples: {len(X_test_text)}\")\n",
    "print()\n",
    "\n",
    "# Step 2: Convert labels to binary matrix\n",
    "print(\"Step 2: Convert Labels to Binary Format\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=categories)\n",
    "mlb.fit([categories])  # Fit on all categories\n",
    "\n",
    "y_train_binary = mlb.transform(y_train_labels)\n",
    "y_test_binary = mlb.transform(y_test_labels)\n",
    "\n",
    "print(f\"Binary matrix shape: {y_train_binary.shape}\")\n",
    "print(f\"Categories: {mlb.classes_}\")\n",
    "print()\n",
    "\n",
    "# Check label distribution in training data\n",
    "print(\"Training label distribution:\")\n",
    "for i, cat in enumerate(categories):\n",
    "    count = y_train_binary[:, i].sum()\n",
    "    print(f\"  {cat:15s}: {count:3d} ({count/len(y_train_binary)*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Step 3: Extract TF-IDF features\n",
    "print(\"Step 3: Extract TF-IDF Features\")\n",
    "print(\"-\" * 50)\n",
    "# TF-IDF with n-grams (following paper's approach)\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,      # Top 1000 features\n",
    "    ngram_range=(1, 2),     # Unigrams and bigrams\n",
    "    min_df=2,               # Minimum document frequency\n",
    "    max_df=0.8,             # Maximum document frequency\n",
    "    stop_words='english',   # Remove common English words\n",
    "    lowercase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24041d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (320, 308)\n",
      "Vocabulary size: 308\n",
      "Sample features learned:\n",
      "  ['10' '10 years' '11' '15' '15 years' '1968' '20' '20 pack' '20 years'\n",
      " '25' '27' '2ppd' '30' '30 years' '40' '40 years' '50' '50 years' 'abc'\n",
      " 'abuse']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit on training data\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf.transform(X_test_text)\n",
    "print(f\"TF-IDF matrix shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Vocabulary size: {len(tfidf.vocabulary_)}\")\n",
    "# Show some top features\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "print(\"Sample features learned:\")\n",
    "print(f\"  {feature_names[:20]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e88d2622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Train XGBoost Classifiers\n",
      "--------------------------------------------------\n",
      "Training multi-label XGBoost (10 binary classifiers)...\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:27:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:27:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:27:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:27:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:27:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:27:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:27:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:27:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:27:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:27:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Training complete!\n",
      "\n",
      "======================================================================\n",
      "PHASE 2 COMPLETE: XGBoost Model Trained!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nothing wrong below syntax wise, but there are certain categories have 0 samples in training data(food, transportation, housing)\n",
    "#  XGBoost can't train a binary classifier when there are no positive examples!\n",
    "# Step 4: Train XGBoost (one classifier per category)\n",
    "print(\"Step 4: Train XGBoost Classifiers\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Training multi-label XGBoost (10 binary classifiers)...\")\n",
    "print()\n",
    "\n",
    "# XGBoost parameters (following paper's approach)\n",
    "xgb_params = {\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'use_label_encoder': False,\n",
    "    'base_score': 0.5,  # any float between 0 and 1\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Train one classifier per category (multi-label approach)\n",
    "xgb_classifiers = MultiOutputClassifier(\n",
    "    xgb.XGBClassifier(**xgb_params)\n",
    ")\n",
    "\n",
    "print(\"Training...\")\n",
    "xgb_classifiers.fit(X_train_tfidf, y_train_binary)\n",
    "print(\"‚úì Training complete!\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PHASE 2 COMPLETE: XGBoost Model Trained!\")\n",
    "print(\"=\"*70)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99ce387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 3: EVALUATING XGBOOST ON 200 TEST SAMPLES\n",
      "======================================================================\n",
      "\n",
      "Making predictions with XGBoost...\n",
      "‚úì Got predictions! Shape: (200, 10)\n",
      "\n",
      "Sample predictions (first 3):\n",
      "  1. Text: Semi-retired Attorney...\n",
      "     Gold:      []\n",
      "     Predicted: []\n",
      "\n",
      "  2. Text: He does not smoke, occasionally drinks alcohol...\n",
      "     Gold:      ['alcohol']\n",
      "     Predicted: ['drug_use', 'alcohol']\n",
      "\n",
      "  3. Text: A 76-year-old who used to smoke a pack a day and quit in 198...\n",
      "     Gold:      ['smoking']\n",
      "     Predicted: ['smoking']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"======================================================================\")\n",
    "print(\"PHASE 3: EVALUATING XGBOOST ON 200 TEST SAMPLES\")\n",
    "print(\"======================================================================\")\n",
    "print()\n",
    "\n",
    "# Make predictions\n",
    "print(\"Making predictions with XGBoost...\")\n",
    "y_pred_binary = xgb_classifiers.predict(X_test_tfidf)\n",
    "\n",
    "print(f\"‚úì Got predictions! Shape: {y_pred_binary.shape}\")\n",
    "print()\n",
    "\n",
    "# Convert binary predictions back to label lists\n",
    "y_pred_labels = mlb.inverse_transform(y_pred_binary)\n",
    "y_pred_labels = [list(labels) for labels in y_pred_labels]\n",
    "\n",
    "# Show first 3 predictions\n",
    "print(\"Sample predictions (first 3):\")\n",
    "for i in range(3):\n",
    "    print(f\"  {i+1}. Text: {X_test_text[i][:60]}...\")\n",
    "    print(f\"     Gold:      {y_test_labels[i]}\")\n",
    "    print(f\"     Predicted: {y_pred_labels[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5e4a6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Performance on 200 Test Samples:\n",
      "  F1 (micro):     0.560\n",
      "  Precision:      0.646\n",
      "  Recall:         0.494\n",
      "  Cohen's Kappa:  0.543\n",
      "  Exact Match:    0.755\n",
      "\n",
      "Comparison:\n",
      "  GPT-4o-mini (best): F1 = 0.940\n",
      "  XGBoost:            F1 = 0.560\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for XGBoost\n",
    "y_pred_parsed_labels=[parse_llm_labels(label) for label in y_pred_labels]\n",
    "xgb_metrics = calculate_multilabel_metrics(\n",
    "    gold_labels=y_test_labels,\n",
    "    predicted_labels=y_pred_parsed_labels,\n",
    "    categories=categories\n",
    ")\n",
    "\n",
    "print(\"XGBoost Performance on 200 Test Samples:\")\n",
    "print(f\"  F1 (micro):     {xgb_metrics['f1_micro']:.3f}\")\n",
    "print(f\"  Precision:      {xgb_metrics['precision_micro']:.3f}\")\n",
    "print(f\"  Recall:         {xgb_metrics['recall_micro']:.3f}\")\n",
    "print(f\"  Cohen's Kappa:  {xgb_metrics['cohen_kappa']:.3f}\")\n",
    "print(f\"  Exact Match:    {xgb_metrics['exact_match_accuracy']:.3f}\")\n",
    "print()\n",
    "\n",
    "# Compare to GPT-4o-mini best result\n",
    "print(\"Comparison:\")\n",
    "print(f\"  GPT-4o-mini (best): F1 = {final_best_model['f1_micro']:.3f}\")\n",
    "print(f\"  XGBoost:            F1 = {xgb_metrics['f1_micro']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "90694b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-category Performance:\n",
      "\n",
      "food           : F1=0.000  P=0.000  R=0.000  (Gold=0, Pred=0)\n",
      "opioids        : F1=0.000  P=0.000  R=0.000  (Gold=2, Pred=0)\n",
      "cocaine        : F1=0.000  P=0.000  R=0.000  (Gold=2, Pred=0)\n",
      "smoking        : F1=0.793  P=0.920  R=0.697  (Gold=33, Pred=25)\n",
      "marijuana      : F1=0.000  P=0.000  R=0.000  (Gold=3, Pred=0)\n",
      "transportation : F1=0.000  P=0.000  R=0.000  (Gold=1, Pred=0)\n",
      "housing        : F1=0.000  P=0.000  R=0.000  (Gold=1, Pred=0)\n",
      "employment     : F1=0.286  P=0.250  R=0.333  (Gold=3, Pred=4)\n",
      "drug_use       : F1=0.000  P=0.000  R=0.000  (Gold=7, Pred=10)\n",
      "alcohol        : F1=0.600  P=0.667  R=0.545  (Gold=33, Pred=27)\n"
     ]
    }
   ],
   "source": [
    "print(\"Per-category Performance:\")\n",
    "print()\n",
    "\n",
    "# Get per-category metrics\n",
    "for i, cat in enumerate(categories):\n",
    "    # Extract this category's predictions\n",
    "    y_true_cat = y_test_binary[:, i]\n",
    "    y_pred_cat = y_pred_binary[:, i]\n",
    "    \n",
    "    tp = ((y_true_cat == 1) & (y_pred_cat == 1)).sum()\n",
    "    fp = ((y_true_cat == 0) & (y_pred_cat == 1)).sum()\n",
    "    fn = ((y_true_cat == 1) & (y_pred_cat == 0)).sum()\n",
    "    \n",
    "    if tp + fp > 0:\n",
    "        precision = tp / (tp + fp)\n",
    "    else:\n",
    "        precision = 0\n",
    "        \n",
    "    if tp + fn > 0:\n",
    "        recall = tp / (tp + fn)\n",
    "    else:\n",
    "        recall = 0\n",
    "        \n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    print(f\"{cat:15s}: F1={f1:.3f}  P={precision:.3f}  R={recall:.3f}  (Gold={y_true_cat.sum()}, Pred={y_pred_cat.sum()})\")\n",
    "\n",
    "# XGBoost is only predicting 3 categories well:\n",
    "\n",
    "# ‚úÖ smoking: F1=0.793 (33 gold samples - enough data!)\n",
    "# ‚ö†Ô∏è alcohol: F1=0.600 (33 gold samples)\n",
    "# ‚ùå employment: F1=0.286 (only 3 gold samples)\n",
    "\n",
    "# XGBoost predicts NOTHING for rare categories:\n",
    "\n",
    "# opioids, cocaine, marijuana, transportation, housing = 0 predictions\n",
    "# drug_use = predicts 10 but all wrong (F1=0.000)\n",
    "\n",
    "# The root cause: XGBoost trained on 320 samples where these rare categories had almost no examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6855a659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Hybrid Model: XGBoost + GPT-4o-mini\n",
      "======================================================================\n",
      "\n",
      "XGBoost handles: ['smoking', 'alcohol']\n",
      "GPT-4o-mini handles: ['food', 'opioids', 'cocaine', 'marijuana', 'transportation', 'housing', 'employment', 'drug_use']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We need a hybrid approach: Use XGBoost for common categories, GPT-4o-mini for rare ones.\n",
    "print(\"Creating Hybrid Model: XGBoost + GPT-4o-mini\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Categories with good XGBoost performance (F1 > 0.5)\n",
    "xgb_categories = ['smoking', 'alcohol']\n",
    "\n",
    "# Categories to use GPT-4o-mini for\n",
    "gpt_categories = ['food', 'opioids', 'cocaine', 'marijuana', \n",
    "                  'transportation', 'housing', 'employment', 'drug_use']\n",
    "\n",
    "print(f\"XGBoost handles: {xgb_categories}\")\n",
    "print(f\"GPT-4o-mini handles: {gpt_categories}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ce61170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Hybrid Predictions...\n",
      "\n",
      "‚úì Got 200 GPT-4o-mini predictions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Hybrid Predictions...\")\n",
    "print()\n",
    "\n",
    "# We need GPT-4o-mini predictions on test set\n",
    "# Do you have them already? Let me check...\n",
    "\n",
    "# From your artifacts, you have: full_results['2-Shot Easy']\n",
    "gpt_predictions = full_results['2-Shot Easy']\n",
    "\n",
    "print(f\"‚úì Got {len(gpt_predictions)} GPT-4o-mini predictions\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a92140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample hybrid predictions:\n",
      "  1. Gold: []\n",
      "     GPT:  []\n",
      "     XGB:  []\n",
      "     Hybrid: []\n",
      "\n",
      "  2. Gold: ['alcohol']\n",
      "     GPT:  [\"alcohol\"]\n",
      "     XGB:  ['drug_use', 'alcohol']\n",
      "     Hybrid: ['alcohol']\n",
      "\n",
      "  3. Gold: ['smoking']\n",
      "     GPT:  [\"smoking\"]\n",
      "     XGB:  ['smoking']\n",
      "     Hybrid: ['smoking']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create hybrid predictions\n",
    "hybrid_predictions = []\n",
    "\n",
    "for i in range(len(y_test_labels)):\n",
    "    # Start with GPT-4o-mini prediction\n",
    "    gpt_pred = parse_llm_labels(gpt_predictions[i]) if gpt_predictions[i] else []\n",
    "    \n",
    "    # Get XGBoost prediction for this sample\n",
    "    xgb_pred = y_pred_labels[i]\n",
    "    \n",
    "    # Combine: Use XGBoost for smoking/alcohol, GPT for everything else\n",
    "    hybrid = []\n",
    "    \n",
    "    # Add XGBoost predictions for smoking and alcohol\n",
    "    if 'smoking' in xgb_pred:\n",
    "        hybrid.append('smoking')\n",
    "    if 'alcohol' in xgb_pred:\n",
    "        hybrid.append('alcohol')\n",
    "    \n",
    "    # Add GPT predictions for all other categories\n",
    "    for label in gpt_pred:\n",
    "        if label not in ['smoking', 'alcohol'] and label not in hybrid:\n",
    "            hybrid.append(label)\n",
    "    \n",
    "    hybrid_predictions.append(hybrid)\n",
    "\n",
    "# Show first 3\n",
    "print(\"Sample hybrid predictions:\")\n",
    "for i in range(3):\n",
    "    print(f\"  {i+1}. Gold: {y_test_labels[i]}\")\n",
    "    print(f\"     GPT:  {gpt_predictions[i]}\")\n",
    "    print(f\"     XGB:  {y_pred_labels[i]}\")\n",
    "    print(f\"     Hybrid: {hybrid_predictions[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cda9cf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Performance on 200 Test Samples:\n",
      "  F1 (micro):     0.659\n",
      "  Precision:      0.671\n",
      "  Recall:         0.647\n",
      "  Cohen's Kappa:  0.644\n",
      "  Exact Match:    0.730\n",
      "\n",
      "Comparison:\n",
      "  GPT-4o-mini (best): F1 = 0.940\n",
      "  XGBoost:            F1 = 0.659\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for XGBoost\n",
    "xgb_metrics = calculate_multilabel_metrics(\n",
    "    gold_labels=y_test_labels,\n",
    "    predicted_labels=hybrid_predictions,\n",
    "    categories=categories\n",
    ")\n",
    "\n",
    "print(\"XGBoost Performance on 200 Test Samples:\")\n",
    "print(f\"  F1 (micro):     {xgb_metrics['f1_micro']:.3f}\")\n",
    "print(f\"  Precision:      {xgb_metrics['precision_micro']:.3f}\")\n",
    "print(f\"  Recall:         {xgb_metrics['recall_micro']:.3f}\")\n",
    "print(f\"  Cohen's Kappa:  {xgb_metrics['cohen_kappa']:.3f}\")\n",
    "print(f\"  Exact Match:    {xgb_metrics['exact_match_accuracy']:.3f}\")\n",
    "print()\n",
    "\n",
    "# Compare to GPT-4o-mini best result\n",
    "print(\"Comparison:\")\n",
    "print(f\"  GPT-4o-mini (best): F1 = {final_best_model['f1_micro']:.3f}\")\n",
    "print(f\"  XGBoost:            F1 = {xgb_metrics['f1_micro']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e92d33d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the Training Data Quality Issue:\n",
      "======================================================================\n",
      "\n",
      "Training Data:\n",
      "  Samples: 320\n",
      "  Labeled by: GPT-4o-mini\n",
      "  Quality: F1 = 0.882 (10% error rate)\n",
      "\n",
      "The Problem:\n",
      "  XGBoost learned from noisy labels with 10% errors\n",
      "  It amplified these errors, especially for rare categories\n",
      "\n",
      "Why GPT-4o-mini is better:\n",
      "  GPT-4o-mini direct:  F1 = 0.940\n",
      "  XGBoost (learned):   F1 = 0.556\n",
      "  Hybrid approach:     F1 = 0.667\n",
      "\n",
      "Conclusion:\n",
      "  ‚ùå XGBoost didn't help - it made things worse!\n",
      "  ‚úÖ Stick with GPT-4o-mini (F1 = 0.940)\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing the Training Data Quality Issue:\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(f\"  Samples: 320\")\n",
    "print(f\"  Labeled by: GPT-4o-mini\")\n",
    "print(f\"  Quality: F1 = {metrics_gpt4o_on_320['f1_micro']:.3f} (10% error rate)\")\n",
    "print()\n",
    "\n",
    "print(\"The Problem:\")\n",
    "print(\"  XGBoost learned from noisy labels with 10% errors\")\n",
    "print(\"  It amplified these errors, especially for rare categories\")\n",
    "print()\n",
    "\n",
    "print(\"Why GPT-4o-mini is better:\")\n",
    "print(f\"  GPT-4o-mini direct:  F1 = 0.940\")\n",
    "print(f\"  XGBoost (learned):   F1 = 0.556\")  \n",
    "print(f\"  Hybrid approach:     F1 = 0.667\")\n",
    "print()\n",
    "\n",
    "print(\"Conclusion:\")\n",
    "print(\"  ‚ùå XGBoost didn't help - it made things worse!\")\n",
    "print(\"  ‚úÖ Stick with GPT-4o-mini (F1 = 0.940)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40a6ba7",
   "metadata": {},
   "source": [
    "#### Test with another option to see if XGBoost performance can be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa4d5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes=categories)\n",
    "mlb.fit([categories])  # Fit on all categories\n",
    "y_test=[parse_llm_labels(label) for label in test_df['gold_labels']]\n",
    "y_test_binary=mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a4886ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "OPTION B: TRAINING XGBOOST ON GOLD LABELS (200 SAMPLES)\n",
      "======================================================================\n",
      "\n",
      "Strategy: Use the 200 test samples with gold labels for training\n",
      "Problem: We need a separate test set to evaluate!\n",
      "\n",
      "Splitting 200 gold-labeled samples:\n",
      "  Training: 150 samples\n",
      "  Testing:  50 samples\n",
      "\n",
      "‚úì Training set: 150 samples\n",
      "‚úì Test set: 50 samples\n",
      "\n",
      "Extracting TF-IDF features...\n",
      "‚úì TF-IDF shape: (150, 143)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"OPTION B: TRAINING XGBOOST ON GOLD LABELS (200 SAMPLES)\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "print(\"Strategy: Use the 200 test samples with gold labels for training\")\n",
    "print(\"Problem: We need a separate test set to evaluate!\")\n",
    "print()\n",
    "\n",
    "# Split the 200 samples: 150 train, 50 test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Splitting 200 gold-labeled samples:\")\n",
    "print(\"  Training: 150 samples\")\n",
    "print(\"  Testing:  50 samples\")\n",
    "print()\n",
    " \n",
    "# Split\n",
    "X_train_gold, X_test_gold, y_train_gold, y_test_gold = train_test_split(\n",
    "    test_df['premise'].values,\n",
    "    y_test_binary,\n",
    "    test_size=50,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"‚úì Training set: {len(X_train_gold)} samples\")\n",
    "print(f\"‚úì Test set: {len(X_test_gold)} samples\")\n",
    "print()\n",
    "\n",
    "# Extract TF-IDF features\n",
    "print(\"Extracting TF-IDF features...\")\n",
    "tfidf_gold = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    stop_words='english',\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "X_train_gold_tfidf = tfidf_gold.fit_transform(X_train_gold)\n",
    "X_test_gold_tfidf = tfidf_gold.transform(X_test_gold)\n",
    "\n",
    "print(f\"‚úì TF-IDF shape: {X_train_gold_tfidf.shape}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e9a5e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost on 150 gold-labeled samples...\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:43:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:43:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:43:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:43:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:43:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:44:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:44:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:44:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:44:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/proj/sas/ripython/venv_311/lib64/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:44:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Training complete!\n",
      "\n",
      "Making predictions with XGBoost...\n",
      "‚úì Got predictions! Shape: (50, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training XGBoost on 150 gold-labeled samples...\")\n",
    "print()\n",
    "xgb_gold=MultiOutputClassifier(xgb.XGBClassifier(**xgb_params))\n",
    "print(\"Training...\")\n",
    "xgb_gold.fit(X_train_gold_tfidf, y_train_gold)\n",
    "print(\"‚úì Training complete!\")\n",
    "print()\n",
    "print(\"Making predictions with XGBoost...\")\n",
    "y_pred_gold_binary=xgb_gold.predict(X_test_gold_tfidf)\n",
    "print(f\"‚úì Got predictions! Shape: {y_pred_gold_binary.shape}\")\n",
    "print() \n",
    "# convert binary back to label lists\n",
    "y_pred_gold_labels=mlb.inverse_transform(y_pred_gold_binary)\n",
    "y_pred_gold_labels=[list(labels) for labels in y_pred_gold_labels]\n",
    "\n",
    "y_test_gold_labels = mlb.inverse_transform(y_test_gold)\n",
    "y_test_gold_labels = [list(labels) for labels in y_test_gold_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dba6ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions (first 3):\n",
      "  1. Text: She is a student...\n",
      "     Gold:      []\n",
      "     Predicted: []\n",
      "\n",
      "  2. Text: She lives with a room-mate....\n",
      "     Gold:      []\n",
      "     Predicted: []\n",
      "\n",
      "  3. Text: Occasional glass of wine at dinner...\n",
      "     Gold:      ['alcohol']\n",
      "     Predicted: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show first 3 predictions\n",
    "print(\"Sample predictions (first 3):\")\n",
    "for i in range(3):\n",
    "    print(f\"  {i+1}. Text: {X_test_gold[i][:60]}...\")\n",
    "    print(f\"     Gold:      {y_test_gold_labels[i]}\")\n",
    "    print(f\"     Predicted: {y_pred_gold_labels[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a5c3174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost trained on GOLD labels (150 samples):\n",
      "  F1 (micro):     0.480\n",
      "  Precision:      0.667\n",
      "  Recall:         0.375\n",
      "  Cohen's Kappa:  0.468\n",
      "  Exact Match:    0.780\n",
      "\n",
      "Comparison:\n",
      "  XGBoost on noisy (320): F1 = 0.556\n",
      "  XGBoost on gold (150):  F1 = 0.480\n",
      "  GPT-4o-mini direct:     F1 = 0.940\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for XGBoost \n",
    "\n",
    "metrics_gold = calculate_multilabel_metrics(\n",
    "    gold_labels=y_test_gold_labels,\n",
    "    predicted_labels=y_pred_gold_labels,\n",
    "    categories=categories\n",
    ")\n",
    "\n",
    "print(\"XGBoost trained on GOLD labels (150 samples):\")\n",
    "print(f\"  F1 (micro):     {metrics_gold['f1_micro']:.3f}\")\n",
    "print(f\"  Precision:      {metrics_gold['precision_micro']:.3f}\")\n",
    "print(f\"  Recall:         {metrics_gold['recall_micro']:.3f}\")\n",
    "print(f\"  Cohen's Kappa:  {metrics_gold['cohen_kappa']:.3f}\")\n",
    "print(f\"  Exact Match:    {metrics_gold['exact_match_accuracy']:.3f}\")\n",
    "print()\n",
    "print(\"Comparison:\")\n",
    "print(f\"  XGBoost on noisy (320): F1 = 0.556\")\n",
    "print(f\"  XGBoost on gold (150):  F1 = {metrics_gold['f1_micro']:.3f}\")\n",
    "print(f\"  GPT-4o-mini direct:     F1 = 0.940\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c755e1f",
   "metadata": {},
   "source": [
    "üöÄ Option C: Confidence-Based Hybrid. The idea: Use XGBoost's prediction probabilities instead of hard predictions. Only trust XGBoost when it's very confident!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfaaac8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "OPTION C: CONFIDENCE-BASED HYBRID\n",
      "======================================================================\n",
      "\n",
      "Strategy: Use prediction confidence scores\n",
      "  - If XGBoost is VERY confident (>0.8), use XGBoost\n",
      "  - Otherwise, use GPT-4o-mini\n",
      "\n",
      "Getting XGBoost confidence scores...\n",
      "‚úì Got probability predictions\n",
      "  Shape: 10 classifiers\n",
      "\n",
      "Sample probabilities for first test sample:\n",
      "  food           : 0.003\n",
      "  opioids        : 0.003\n",
      "  cocaine        : 0.004\n",
      "  smoking        : 0.012\n",
      "  marijuana      : 0.002\n",
      "  transportation : 0.003\n",
      "  housing        : 0.003\n",
      "  employment     : 0.014\n",
      "  drug_use       : 0.025\n",
      "  alcohol        : 0.032\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"OPTION C: CONFIDENCE-BASED HYBRID\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "print(\"Strategy: Use prediction confidence scores\")\n",
    "print(\"  - If XGBoost is VERY confident (>0.8), use XGBoost\")\n",
    "print(\"  - Otherwise, use GPT-4o-mini\")\n",
    "print()\n",
    "\n",
    "# Get XGBoost probability predictions (not just 0/1)\n",
    "print(\"Getting XGBoost confidence scores...\")\n",
    "xgb_proba = xgb_classifiers.predict_proba(X_test_tfidf)\n",
    "\n",
    "print(f\"‚úì Got probability predictions\")\n",
    "print(f\"  Shape: {len(xgb_proba)} classifiers\")\n",
    "print()\n",
    "\n",
    "# Show sample probabilities for first sample\n",
    "print(\"Sample probabilities for first test sample:\")\n",
    "for i, cat in enumerate(categories):\n",
    "    # Each classifier returns [prob_negative, prob_positive]\n",
    "    prob_positive = xgb_proba[i][0][1]  # Probability of class=1\n",
    "    print(f\"  {cat:15s}: {prob_positive:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f29928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing XGBoost confidence across ALL 200 samples:\n",
      "\n",
      "food           : max=0.003, avg=0.003, min=0.003, >0.5: 0/200\n",
      "opioids        : max=0.063, avg=0.006, min=0.003, >0.5: 0/200\n",
      "cocaine        : max=0.026, avg=0.005, min=0.004, >0.5: 0/200\n",
      "smoking        : max=0.990, avg=0.130, min=0.004, >0.5: 24/200\n",
      "marijuana      : max=0.344, avg=0.016, min=0.001, >0.5: 0/200\n",
      "transportation : max=0.003, avg=0.003, min=0.003, >0.5: 0/200\n",
      "housing        : max=0.003, avg=0.003, min=0.003, >0.5: 0/200\n",
      "employment     : max=0.669, avg=0.029, min=0.006, >0.5: 4/200\n",
      "drug_use       : max=0.924, avg=0.088, min=0.002, >0.5: 10/200\n",
      "alcohol        : max=0.991, avg=0.168, min=0.004, >0.5: 27/200\n",
      "\n",
      "This shows us if XGBoost is confident about ANY samples!\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing XGBoost confidence across ALL 200 samples:\")\n",
    "print()\n",
    "\n",
    "for j, cat in enumerate(categories):\n",
    "    # Get probabilities for this category across all 200 samples\n",
    "    all_probs = xgb_proba[j][:, 1]  # All samples, positive class\n",
    "    \n",
    "    max_prob = all_probs.max()\n",
    "    min_prob = all_probs.min()\n",
    "    avg_prob = all_probs.mean()\n",
    "    \n",
    "    # Count how many samples have high confidence (>0.5)\n",
    "    high_conf_count = (all_probs > 0.5).sum()\n",
    "    \n",
    "    print(f\"{cat:15s}: max={max_prob:.3f}, avg={avg_prob:.3f}, min={min_prob:.3f}, >0.5: {high_conf_count}/200\")\n",
    "\n",
    "print()\n",
    "print(\"This shows us if XGBoost is confident about ANY samples!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10a94f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SMART HYBRID: XGBoost (when confident) + GPT-4o-mini\n",
      "======================================================================\n",
      "\n",
      "Rules:\n",
      "  - smoking/alcohol: Use XGBoost if confidence > 0.5\n",
      "  - Everything else: Use GPT-4o-mini\n",
      "\n",
      "Results:\n",
      "  Smart Hybrid: F1 = 0.659\n",
      "\n",
      "Comparison:\n",
      "  GPT-4o-mini alone:  F1 = 0.940\n",
      "  XGBoost alone:      F1 = 0.564\n",
      "  Smart Hybrid:       F1 = 0.659\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SMART HYBRID: XGBoost (when confident) + GPT-4o-mini\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "print(\"Rules:\")\n",
    "print(\"  - smoking/alcohol: Use XGBoost if confidence > 0.5\")\n",
    "print(\"  - Everything else: Use GPT-4o-mini\")\n",
    "print()\n",
    "\n",
    "# Create smart hybrid predictions\n",
    "smart_hybrid = []\n",
    "\n",
    "for i in range(len(y_test_labels)):\n",
    "    # Start with GPT prediction\n",
    "    gpt_pred = parse_llm_labels(gpt_predictions[i]) if gpt_predictions[i] else []\n",
    "    prediction = list(gpt_pred)\n",
    "    \n",
    "    # Override smoking if XGBoost is confident\n",
    "    smoking_idx = categories.index('smoking')\n",
    "    if xgb_proba[smoking_idx][i][1] > 0.5:\n",
    "        if 'smoking' not in prediction:\n",
    "            prediction.append('smoking')\n",
    "    elif xgb_proba[smoking_idx][i][1] < 0.5:\n",
    "        if 'smoking' in prediction:\n",
    "            prediction.remove('smoking')\n",
    "    \n",
    "    # Override alcohol if XGBoost is confident\n",
    "    alcohol_idx = categories.index('alcohol')\n",
    "    if xgb_proba[alcohol_idx][i][1] > 0.5:\n",
    "        if 'alcohol' not in prediction:\n",
    "            prediction.append('alcohol')\n",
    "    elif xgb_proba[alcohol_idx][i][1] < 0.5:\n",
    "        if 'alcohol' in prediction:\n",
    "            prediction.remove('alcohol')\n",
    "    \n",
    "    smart_hybrid.append(prediction)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics_smart = calculate_multilabel_metrics(\n",
    "    gold_labels=y_test_labels,\n",
    "    predicted_labels=smart_hybrid,\n",
    "    categories=categories\n",
    ")\n",
    "\n",
    "print(\"Results:\")\n",
    "print(f\"  Smart Hybrid: F1 = {metrics_smart['f1_micro']:.3f}\")\n",
    "print()\n",
    "print(\"Comparison:\")\n",
    "print(f\"  GPT-4o-mini alone:  F1 = 0.940\")\n",
    "print(f\"  XGBoost alone:      F1 = 0.564\")\n",
    "print(f\"  Smart Hybrid:       F1 = {metrics_smart['f1_micro']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260d34d8",
   "metadata": {},
   "source": [
    "### XGBoost Failed:\n",
    "***Root Causes***:\n",
    "- Small dataset: 320 training samples insufficient for 10 categories\n",
    "- Severe class imbalance: 6/10 categories had <5 training examples\n",
    "- Noisy training labels: GPT-4o-mini labels had 10-12% error rate (F1=0.88-0.90)\n",
    "- Variability in LLM labels: Running GPT-4o-mini twice on same 320 samples gave F1=0.90 then F1=0.88,<br>\n",
    "\n",
    "***Comparison to Paper (arxiv 2407.17126)***:<br>\n",
    "The Paper:<br>\n",
    "- Used LLM ‚Üí XGBoost approach (same as you!) \n",
    "- Likely had 1000s of training samples (not 320) \n",
    "- Better class balance \n",
    "- Achieved 0.90+ AUROC \n",
    "\n",
    "***Your Work:***<br>\n",
    "- Only 320 samples\n",
    "- 6 categories with <5 examples each\n",
    "- XGBoost couldn't learn rare categories\n",
    "\n",
    "***Conclusion: Your approach was correct; you just need more data to make XGBoost competitive!<br>***\n",
    "\n",
    "***FINAL RESULTS COMPARISON:<br>***\n",
    "Model|                          F1 Score\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "GPT-4o-mini (direct)           0.940 ‚úÖ WINNER\n",
    "GPT-3.5 Turbo 2-Shot Easy      0.845 (baseline)\n",
    "XGBoost on noisy (320)         0.564\n",
    "Hybrid (simple)                0.667\n",
    "Smart Hybrid (confidence)      0.659\n",
    "XGBoost on gold (150)          0.480\n",
    "\n",
    "***KEY TECHNICAL DETAILS***\n",
    "***Data Split:***\n",
    "\n",
    "- 570 total samples\n",
    "- 50 used for hard example selection\n",
    "- 200 used for testing (gold labels)\n",
    "- 320 unused samples (used for XGBoost training)\n",
    "\n",
    "***Categories:***\n",
    "food, opioids, cocaine, smoking, marijuana, transportation, housing, employment, drug_use, alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc18284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Configuration:\n",
    "xgb_params = {\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'random_state': 42\n",
    "}\n",
    "# TF-IDF Features:\n",
    "TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    stop_words='english',\n",
    "    lowercase=True\n",
    ") \n",
    "## **CODE ARTIFACTS YOU HAVE**\n",
    "\n",
    "1. `llm_utils.py` - All helper functions\n",
    "2. `sdoh_data.py` - Data loading\n",
    "3. Hard example selection code\n",
    "4. Easy example selection code\n",
    "5. Prompt engineering evaluation code\n",
    "6. GPT-4o-mini strengthened prompt\n",
    "7. XGBoost training & evaluation code\n",
    "8. Hybrid model code\n",
    "9. Confidence analysis code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15a856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
